{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Анализ датасета Brain tumor\n",
    "\n",
    "Напишите код, использующий библиотеку Ludwig, для решения задачи из датасета.\n",
    "https://www.kaggle.com/navoneel/brain-mri-images-for-brain-tumor-detection\n",
    "\n",
    "Импортируем библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определяем функцию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listdir_fullpath(d):\n",
    "    return [os.path.join(d, f) for f in os.listdir(d)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем списки с файлами из папок yes и no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_yes = listdir_fullpath('brain_tumor_dataset/yes')\n",
    "ls_no = listdir_fullpath('brain_tumor_dataset/no')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем датафрейм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt1 = np.array(np.column_stack((ls_yes, np.ones(len(ls_yes)))))\n",
    "dt2 = np.array(np.column_stack((ls_no, np.zeros(len(ls_no)))))\n",
    "dt = np.vstack((dt1,dt2))\n",
    "data = pd.DataFrame(data = dt, columns = ['fname', 'label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем списки тренировочных и тестовых данных, предварительно перемешав данные, переводим в формат csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(frac=1).reset_index(drop=True) \n",
    "\n",
    "data_train = data[0:200]\n",
    "data_test = data[200:254]\n",
    "\n",
    "data_train.to_csv('data_train.csv', index=None)\n",
    "data_test.to_csv('data_test.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Устанавливаем людвиг для изображений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ludwig[image]\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/b6/8c5d8ee36997f31c1e9756b5ebb83d942f21e79287453cd525eac46e5801/ludwig-0.2.2.7.tar.gz (172kB)\n",
      "\u001b[K     |████████████████████████████████| 174kB 752kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: Cython>=0.25 in /opt/anaconda3/lib/python3.7/site-packages (from ludwig[image]) (0.29.13)\n",
      "Requirement already satisfied: h5py>=2.6 in /opt/anaconda3/lib/python3.7/site-packages (from ludwig[image]) (2.9.0)\n",
      "Requirement already satisfied: numpy>=1.15 in /opt/anaconda3/lib/python3.7/site-packages (from ludwig[image]) (1.17.2)\n",
      "Requirement already satisfied: pandas>=0.19 in /opt/anaconda3/lib/python3.7/site-packages (from ludwig[image]) (0.25.1)\n",
      "Requirement already satisfied: scipy>=0.18 in /opt/anaconda3/lib/python3.7/site-packages (from ludwig[image]) (1.3.1)\n",
      "Collecting tabulate>=0.7 (from ludwig[image])\n",
      "  Downloading https://files.pythonhosted.org/packages/c4/f4/770ae9385990f5a19a91431163d262182d3203662ea2b5739d0fcfc080f1/tabulate-0.8.7-py3-none-any.whl\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.7/site-packages (from ludwig[image]) (0.21.3)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.7/site-packages (from ludwig[image]) (4.36.1)\n",
      "Collecting tensorflow==1.15.3 (from ludwig[image])\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/78/c1/88049aa5ca4248207cfe5b47a4b5d11f98afa93a8dc303008d151891b18a/tensorflow-1.15.3-cp37-cp37m-macosx_10_11_x86_64.whl (123.4MB)\n",
      "\u001b[K     |████████████████████████████████| 123.4MB 227kB/s  eta 0:00:01    |███████████▊                    | 45.2MB 10.1MB/s eta 0:00:08     |███████████████████████████▍    | 105.6MB 10.5MB/s eta 0:00:02\n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=3.12 in /opt/anaconda3/lib/python3.7/site-packages (from ludwig[image]) (5.1.2)\n",
      "Collecting absl-py (from ludwig[image])\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/53/9243c600e047bd4c3df9e69cfabc1e8004a82cac2e0c484580a78a94ba2a/absl-py-0.9.0.tar.gz (104kB)\n",
      "\u001b[K     |████████████████████████████████| 112kB 2.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scikit-image==0.14.2 (from ludwig[image])\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/84/c4/0632e710fb581f47b43cb6b1c9985fa1c7431d1087e6153a10694a56f4a6/scikit_image-0.14.2-cp37-cp37m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (28.8MB)\n",
      "\u001b[K     |████████████████████████████████| 28.8MB 5.5MB/s eta 0:00:011     |████████████████████████▍       | 22.0MB 5.5MB/s eta 0:00:02     |████████████████████████████▋   | 25.8MB 5.5MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /opt/anaconda3/lib/python3.7/site-packages (from h5py>=2.6->ludwig[image]) (1.12.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/anaconda3/lib/python3.7/site-packages (from pandas>=0.19->ludwig[image]) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/anaconda3/lib/python3.7/site-packages (from pandas>=0.19->ludwig[image]) (2.8.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/anaconda3/lib/python3.7/site-packages (from scikit-learn->ludwig[image]) (0.13.2)\n",
      "Collecting astor>=0.6.0 (from tensorflow==1.15.3->ludwig[image])\n",
      "  Downloading https://files.pythonhosted.org/packages/c3/88/97eef84f48fa04fbd6750e62dcceafba6c63c81b7ac1420856c8dcc0a3f9/astor-0.8.1-py2.py3-none-any.whl\n",
      "Collecting tensorboard<1.16.0,>=1.15.0 (from tensorflow==1.15.3->ludwig[image])\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8MB 10.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting termcolor>=1.1.0 (from tensorflow==1.15.3->ludwig[image])\n",
      "  Downloading https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.15.3->ludwig[image]) (1.11.2)\n",
      "Collecting keras-preprocessing>=1.0.5 (from tensorflow==1.15.3->ludwig[image])\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/79/4c/7c3275a01e12ef9368a892926ab932b33bb13d55794881e3573482b378a7/Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 5.6MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting protobuf>=3.6.1 (from tensorflow==1.15.3->ludwig[image])\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/12/b5/9347e30e11c040f5ca24f079d6f06485280c49b2a9f894b5400e27d4d6d1/protobuf-3.12.2-cp37-cp37m-macosx_10_9_x86_64.whl (1.3MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3MB 10.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-pasta>=0.1.6 (from tensorflow==1.15.3->ludwig[image])\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/de/c648ef6835192e6e2cc03f40b19eeda4382c49b5bafb43d88b931c4c74ac/google_pasta-0.2.0-py3-none-any.whl (57kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 7.4MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.26; python_version >= \"3\" in /opt/anaconda3/lib/python3.7/site-packages (from tensorflow==1.15.3->ludwig[image]) (0.33.6)\n",
      "Collecting tensorflow-estimator==1.15.1 (from tensorflow==1.15.3->ludwig[image])\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
      "\u001b[K     |████████████████████████████████| 512kB 5.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2 (from tensorflow==1.15.3->ludwig[image])\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/a5/e6c07b08b934831ccb8c98ee335e66b7761c5754ee3cabfe4c11d0b1af28/opt_einsum-3.2.1-py3-none-any.whl (63kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 8.9MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting gast==0.2.2 (from tensorflow==1.15.3->ludwig[image])\n",
      "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
      "Collecting grpcio>=1.8.6 (from tensorflow==1.15.3->ludwig[image])\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/75/5a949d048d96ecb3c304f14975f8a0965cb0d3c3f5f5f6b3f4e15c3d49eb/grpcio-1.29.0-cp37-cp37m-macosx_10_9_x86_64.whl (2.8MB)\n",
      "\u001b[K     |████████████████████████████████| 2.8MB 9.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras-applications>=1.0.8 (from tensorflow==1.15.3->ludwig[image])\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 7.9MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: cloudpickle>=0.2.1 in /opt/anaconda3/lib/python3.7/site-packages (from scikit-image==0.14.2->ludwig[image]) (1.2.2)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /opt/anaconda3/lib/python3.7/site-packages (from scikit-image==0.14.2->ludwig[image]) (1.0.3)\n",
      "Requirement already satisfied: dask[array]>=1.0.0 in /opt/anaconda3/lib/python3.7/site-packages (from scikit-image==0.14.2->ludwig[image]) (2.5.2)\n",
      "Requirement already satisfied: pillow>=4.3.0 in /opt/anaconda3/lib/python3.7/site-packages (from scikit-image==0.14.2->ludwig[image]) (6.2.0)\n",
      "Requirement already satisfied: matplotlib>=2.0.0 in /opt/anaconda3/lib/python3.7/site-packages (from scikit-image==0.14.2->ludwig[image]) (3.1.1)\n",
      "Requirement already satisfied: networkx>=1.8 in /opt/anaconda3/lib/python3.7/site-packages (from scikit-image==0.14.2->ludwig[image]) (2.3)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.3->ludwig[image])\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/63/eaec2bd025ab48c754b55e8819af0f6a69e2b1e187611dd40cbbe101ee7f/Markdown-3.2.2-py3-none-any.whl (88kB)\n",
      "\u001b[K     |████████████████████████████████| 92kB 7.9MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.15 in /opt/anaconda3/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.3->ludwig[image]) (0.16.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/anaconda3/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.3->ludwig[image]) (41.4.0)\n",
      "Requirement already satisfied: toolz>=0.7.3; extra == \"array\" in /opt/anaconda3/lib/python3.7/site-packages (from dask[array]>=1.0.0->scikit-image==0.14.2->ludwig[image]) (0.10.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.7/site-packages (from matplotlib>=2.0.0->scikit-image==0.14.2->ludwig[image]) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/anaconda3/lib/python3.7/site-packages (from matplotlib>=2.0.0->scikit-image==0.14.2->ludwig[image]) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/anaconda3/lib/python3.7/site-packages (from matplotlib>=2.0.0->scikit-image==0.14.2->ludwig[image]) (2.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/anaconda3/lib/python3.7/site-packages (from networkx>=1.8->scikit-image==0.14.2->ludwig[image]) (4.4.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /opt/anaconda3/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.3->ludwig[image]) (0.23)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/anaconda3/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.3->ludwig[image]) (0.6.0)\n",
      "Requirement already satisfied: more-itertools in /opt/anaconda3/lib/python3.7/site-packages (from zipp>=0.5->importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.3->ludwig[image]) (7.2.0)\n",
      "Building wheels for collected packages: ludwig, absl-py, termcolor, gast\n",
      "  Building wheel for ludwig (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ludwig: filename=ludwig-0.2.2.7-cp37-none-any.whl size=236245 sha256=ad6b9557a00a2fbdef2701dc9c1ed65c50aaafd7e87afe6e8c60ffe18368b426\n",
      "  Stored in directory: /Users/varvarayudina/Library/Caches/pip/wheels/fa/f3/49/074f3056cf991866d89b5893e6e427573cd169c387087d2230\n",
      "  Building wheel for absl-py (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for absl-py: filename=absl_py-0.9.0-cp37-none-any.whl size=121932 sha256=099ddbf26ecb2b925264e25d30bab76cc21f5570c76afdb2154352c456b78fc4\n",
      "  Stored in directory: /Users/varvarayudina/Library/Caches/pip/wheels/8e/28/49/fad4e7f0b9a1227708cbbee4487ac8558a7334849cb81c813d\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-cp37-none-any.whl size=4832 sha256=c53e8bc700b2c5b17b79932ad6d8c986e4caabf88996699e09602577ed935538\n",
      "  Stored in directory: /Users/varvarayudina/Library/Caches/pip/wheels/7c/06/54/bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6\n",
      "  Building wheel for gast (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gast: filename=gast-0.2.2-cp37-none-any.whl size=7540 sha256=f38e2c41ce08eadbc6b9ae1f64d9ab43daf68ccccece9010b8509e634454f251\n",
      "  Stored in directory: /Users/varvarayudina/Library/Caches/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
      "Successfully built ludwig absl-py termcolor gast\n",
      "Installing collected packages: tabulate, astor, markdown, absl-py, protobuf, grpcio, tensorboard, termcolor, keras-preprocessing, google-pasta, tensorflow-estimator, opt-einsum, gast, keras-applications, tensorflow, scikit-image, ludwig\n",
      "  Found existing installation: scikit-image 0.15.0\n",
      "    Uninstalling scikit-image-0.15.0:\n",
      "      Successfully uninstalled scikit-image-0.15.0\n",
      "Successfully installed absl-py-0.9.0 astor-0.8.1 gast-0.2.2 google-pasta-0.2.0 grpcio-1.29.0 keras-applications-1.0.8 keras-preprocessing-1.1.2 ludwig-0.2.2.7 markdown-3.2.2 opt-einsum-3.2.1 protobuf-3.12.2 scikit-image-0.14.2 tabulate-0.8.7 tensorboard-1.15.0 tensorflow-1.15.3 tensorflow-estimator-1.15.1 termcolor-1.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ludwig[image]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тренируем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "███████████████████████\n",
      "█ █ █ █  ▜█ █ █ █ █   █\n",
      "█ █ █ █ █ █ █ █ █ █ ███\n",
      "█ █   █ █ █ █ █ █ █ ▌ █\n",
      "█ █████ █ █ █ █ █ █ █ █\n",
      "█     █  ▟█     █ █   █\n",
      "███████████████████████\n",
      "ludwig v0.2.2.7 - Train\n",
      "\n",
      "Experiment name: experiment\n",
      "Model name: run\n",
      "Output path: results/experiment_run_1\n",
      "\n",
      "\n",
      "ludwig_version: '0.2.2.7'\n",
      "command: ('/opt/anaconda3/bin/ludwig train --data_train_csv data_train.csv '\n",
      " '--data_test_csv data_test.csv --model_definition_file model_definition.yaml')\n",
      "random_seed: 42\n",
      "input_data_train: 'data_train.csv'\n",
      "input_data_test: 'data_test.csv'\n",
      "model_definition: {   'combiner': {'type': 'concat'},\n",
      "    'input_features': [   {   'conv_layers': [   {   'filter_size': 3,\n",
      "                                                     'num_filters': 32,\n",
      "                                                     'pool_size': 2,\n",
      "                                                     'pool_stride': 2},\n",
      "                                                 {   'dropout': True,\n",
      "                                                     'filter_size': 3,\n",
      "                                                     'num_filters': 64,\n",
      "                                                     'pool_size': 2,\n",
      "                                                     'pool_stride': 2}],\n",
      "                              'encoder': 'stacked_cnn',\n",
      "                              'fc_layers': [{'dropout': True, 'fc_size': 128}],\n",
      "                              'name': 'fname',\n",
      "                              'preprocessing': {'num_processes': 4},\n",
      "                              'tied_weights': None,\n",
      "                              'type': 'image'}],\n",
      "    'output_features': [   {   'dependencies': [],\n",
      "                               'loss': {   'class_similarities_temperature': 0,\n",
      "                                           'class_weights': 1,\n",
      "                                           'confidence_penalty': 0,\n",
      "                                           'distortion': 1,\n",
      "                                           'labels_smoothing': 0,\n",
      "                                           'negative_samples': 0,\n",
      "                                           'robust_lambda': 0,\n",
      "                                           'sampler': None,\n",
      "                                           'type': 'softmax_cross_entropy',\n",
      "                                           'unique': False,\n",
      "                                           'weight': 1},\n",
      "                               'name': 'label',\n",
      "                               'reduce_dependencies': 'sum',\n",
      "                               'reduce_input': 'sum',\n",
      "                               'top_k': 3,\n",
      "                               'type': 'category'}],\n",
      "    'preprocessing': {   'audio': {   'audio_feature': {'type': 'raw'},\n",
      "                                      'audio_file_length_limit_in_s': 7.5,\n",
      "                                      'in_memory': True,\n",
      "                                      'missing_value_strategy': 'backfill',\n",
      "                                      'norm': None,\n",
      "                                      'padding_value': 0},\n",
      "                         'bag': {   'fill_value': '<UNK>',\n",
      "                                    'lowercase': False,\n",
      "                                    'missing_value_strategy': 'fill_with_const',\n",
      "                                    'most_common': 10000,\n",
      "                                    'tokenizer': 'space'},\n",
      "                         'binary': {   'fill_value': 0,\n",
      "                                       'missing_value_strategy': 'fill_with_const'},\n",
      "                         'category': {   'fill_value': '<UNK>',\n",
      "                                         'lowercase': False,\n",
      "                                         'missing_value_strategy': 'fill_with_const',\n",
      "                                         'most_common': 10000},\n",
      "                         'date': {   'datetime_format': None,\n",
      "                                     'fill_value': '',\n",
      "                                     'missing_value_strategy': 'fill_with_const'},\n",
      "                         'force_split': False,\n",
      "                         'h3': {   'fill_value': 576495936675512319,\n",
      "                                   'missing_value_strategy': 'fill_with_const'},\n",
      "                         'image': {   'in_memory': True,\n",
      "                                      'missing_value_strategy': 'backfill',\n",
      "                                      'num_processes': 1,\n",
      "                                      'resize_method': 'interpolate',\n",
      "                                      'scaling': 'pixel_normalization'},\n",
      "                         'numerical': {   'fill_value': 0,\n",
      "                                          'missing_value_strategy': 'fill_with_const',\n",
      "                                          'normalization': None},\n",
      "                         'sequence': {   'fill_value': '<UNK>',\n",
      "                                         'lowercase': False,\n",
      "                                         'missing_value_strategy': 'fill_with_const',\n",
      "                                         'most_common': 20000,\n",
      "                                         'padding': 'right',\n",
      "                                         'padding_symbol': '<PAD>',\n",
      "                                         'sequence_length_limit': 256,\n",
      "                                         'tokenizer': 'space',\n",
      "                                         'unknown_symbol': '<UNK>',\n",
      "                                         'vocab_file': None},\n",
      "                         'set': {   'fill_value': '<UNK>',\n",
      "                                    'lowercase': False,\n",
      "                                    'missing_value_strategy': 'fill_with_const',\n",
      "                                    'most_common': 10000,\n",
      "                                    'tokenizer': 'space'},\n",
      "                         'split_probabilities': (0.7, 0.1, 0.2),\n",
      "                         'stratify': None,\n",
      "                         'text': {   'char_most_common': 70,\n",
      "                                     'char_sequence_length_limit': 1024,\n",
      "                                     'char_tokenizer': 'characters',\n",
      "                                     'char_vocab_file': None,\n",
      "                                     'fill_value': '<UNK>',\n",
      "                                     'lowercase': True,\n",
      "                                     'missing_value_strategy': 'fill_with_const',\n",
      "                                     'padding': 'right',\n",
      "                                     'padding_symbol': '<PAD>',\n",
      "                                     'unknown_symbol': '<UNK>',\n",
      "                                     'word_most_common': 20000,\n",
      "                                     'word_sequence_length_limit': 256,\n",
      "                                     'word_tokenizer': 'space_punct',\n",
      "                                     'word_vocab_file': None},\n",
      "                         'timeseries': {   'fill_value': '',\n",
      "                                           'missing_value_strategy': 'fill_with_const',\n",
      "                                           'padding': 'right',\n",
      "                                           'padding_value': 0,\n",
      "                                           'timeseries_length_limit': 256,\n",
      "                                           'tokenizer': 'space'},\n",
      "                         'vector': {   'fill_value': '',\n",
      "                                       'missing_value_strategy': 'fill_with_const'}},\n",
      "    'training': {   'batch_size': 128,\n",
      "                    'bucketing_field': None,\n",
      "                    'decay': False,\n",
      "                    'decay_rate': 0.96,\n",
      "                    'decay_steps': 10000,\n",
      "                    'dropout_rate': 0.4,\n",
      "                    'early_stop': 5,\n",
      "                    'epochs': 10,\n",
      "                    'eval_batch_size': 0,\n",
      "                    'gradient_clipping': None,\n",
      "                    'increase_batch_size_on_plateau': 0,\n",
      "                    'increase_batch_size_on_plateau_max': 512,\n",
      "                    'increase_batch_size_on_plateau_patience': 5,\n",
      "                    'increase_batch_size_on_plateau_rate': 2,\n",
      "                    'learning_rate': 0.001,\n",
      "                    'learning_rate_warmup_epochs': 1,\n",
      "                    'optimizer': {   'beta1': 0.9,\n",
      "                                     'beta2': 0.999,\n",
      "                                     'epsilon': 1e-08,\n",
      "                                     'type': 'adam'},\n",
      "                    'reduce_learning_rate_on_plateau': 0,\n",
      "                    'reduce_learning_rate_on_plateau_patience': 5,\n",
      "                    'reduce_learning_rate_on_plateau_rate': 0.5,\n",
      "                    'regularization_lambda': 0,\n",
      "                    'regularizer': 'l2',\n",
      "                    'staircase': False,\n",
      "                    'validation_field': 'combined',\n",
      "                    'validation_measure': 'loss'}}\n",
      "\n",
      "\n",
      "Using training raw csv, no hdf5 and json file with the same name have been found\n",
      "Building dataset (it may take a while)\n",
      "Loading training csv...\n",
      "done\n",
      "Loading validation csv..\n",
      "done\n",
      "Loading test csv..\n",
      "done\n",
      "Concatenating csvs..\n",
      "done\n",
      "Using 4 processes for preprocessing images\n",
      "multiprocessing.pool.RemoteTraceback: \n",
      "\"\"\"\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/ludwig/features/image_feature.py\", line 138, in _read_image_and_resize\n",
      "    num_channels))\n",
      "ValueError: Image /Users/varvarayudina/brain_tumor_dataset/yes/Y70.jpg has 1 channels, unlike the first image, which has 3 channels. Make sure all the iamges have the samenumber of channels or use the num_channels property inimage preprocessing\n",
      "\"\"\"\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/bin/ludwig\", line 10, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/ludwig/cli.py\", line 118, in main\n",
      "    CLI()\n",
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/ludwig/cli.py\", line 64, in __init__\n",
      "    getattr(self, args.command)()\n",
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/ludwig/cli.py\", line 74, in train\n",
      "    train.cli(sys.argv[2:])\n",
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/ludwig/train.py\", line 809, in cli\n",
      "    full_train(**vars(args))\n",
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/ludwig/train.py\", line 301, in full_train\n",
      "    random_seed=random_seed\n",
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/ludwig/data/preprocessing.py\", line 344, in preprocess_for_training\n",
      "    random_seed=random_seed\n",
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/ludwig/data/preprocessing.py\", line 533, in preprocess_for_training_by_type\n",
      "    random_seed=random_seed\n",
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/ludwig/data/preprocessing.py\", line 660, in _preprocess_csv_for_training\n",
      "    random_seed=random_seed\n",
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/ludwig/data/preprocessing.py\", line 96, in build_dataset_df\n",
      "    global_preprocessing_parameters\n",
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/ludwig/data/preprocessing.py\", line 176, in build_data\n",
      "    preprocessing_parameters\n",
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/ludwig/features/image_feature.py\", line 310, in add_feature_data\n",
      "    pool.map(read_image_and_resize, all_file_paths)\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 268, in map\n",
      "    return self._map_async(func, iterable, mapstar, chunksize).get()\n",
      "  File \"/opt/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 657, in get\n",
      "    raise self._value\n",
      "ValueError: Image /Users/varvarayudina/brain_tumor_dataset/yes/Y70.jpg has 1 channels, unlike the first image, which has 3 channels. Make sure all the iamges have the samenumber of channels or use the num_channels property inimage preprocessing\n"
     ]
    }
   ],
   "source": [
    "!ludwig train --data_train_csv 'data_train.csv' --data_test_csv 'data_test.csv' --model_definition_file model_definition.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "К сожалению последняя команда не работает, так как все изображения разного размера и с разным количеством каналов, и если проблему с размером изображений решить удалось, то что делать с количеством каналов непонятно. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
